**Numerical Analysis MATH50003 (2024â€“25) Revision Sheet**


**Problem 1(a)** State which real number is represented by an IEEE 16-bit floating point number (with $Ïƒ = 15, Q = 5$, and $S = 10$) with bits
$$
{\tt 1\ 01000\ 0000000001}
$$



**Problem 1(b)**  How are the following real numbers rounded to the nearest $F_{16}$?
$$
1/2, 1/2 + 2^{-12}, 3 + 2^{-9} + 2^{-10}, 3 + 2^{-10} + 2^{-11}.
$$



**Problem 2(a)** Consider a Lower triangular matrix with floating point entries:
$$
L = \begin{bmatrix}
â„“_{11} \\
 â„“_{21} & â„“_{22} \\
 â‹® & â‹± & â‹± \\
 â„“_{n1} & â‹¯ & â„“_{n,n-1} & â„“_{nn}
 \end{bmatrix} âˆˆ F_{Ïƒ,Q,S}^{n Ã— n}
$$
and a vector $ğ± \in F_{Ïƒ,Q,S}^{n}$, where $F_{Ïƒ,Q,S}$ is a set of floating-point numbers.
Denoting matrix-vector multiplication implemented using floating point arithmetic as
$$
ğ› := {\tt lowermul}(L,ğ±)
$$
express the entries $b_k := {\bf e}_k^âŠ¤ ğ›$  in terms of $â„“_{kj}$ and $x_k := {\bf e}_k^âŠ¤ ğ±$, 
using rounded floating-point operations $âŠ•$ and $âŠ—$.



**Problem 2(b)** Assuming all operations involve normal floating numbers, show that your approximation has the form
$$
L ğ± = {\tt lowermul}(L, ğ±) + ğ›œ
$$
where, for $Ïµ_{\rm m}$ denoting machine epsilon and $E_{n,Ïµ}:= {n Ïµ \over 1-nÏµ}$ and assuming $n Ïµ_{\rm m} < 2$,
$$
\| ğ›œ \|_1 â‰¤   2E_{n,Ïµ_{\rm m}/2}   \|L\|_1 \| ğ± \|_1.
$$
Here we use  the matrix norm $\| A \|_1 := \max_j âˆ‘_{k=1}^n |a_{kj}|$
and the vector norm $\| ğ± \|_1 := âˆ‘_{k=1}^n |x_k|$. You may use the fact that
$$
x_1 âŠ• â‹¯ âŠ• x_n = x_1 +  â‹¯ + x_n + Ïƒ_n
$$
where
$$
|Ïƒ_n| â‰¤ \| ğ± \|_1 E_{n-1,Ïµ_{\rm m}/2}.
$$






**Problem 3** What is the dual extension of square-roots? I.e. what should $\sqrt{a + b Ïµ}$ equal assuming $a > 0$?







**Problem 4** Use the Cholesky factorisation to determine
whether the following matrix is symmetric positive definite:
$$
\begin{bmatrix} 2 & 2 & 1  \\
2 & 3 & 2\\
1 & 2 & 2
\end{bmatrix}
$$



**Problem 5** Use reflections to determine the entries of an orthogonal matrix $Q$ such that
$$
Q \begin{bmatrix} 2 \\ 1 \\ 2 \end{bmatrix} =  \begin{bmatrix} -3 \\ 0 \\ 0 \end{bmatrix}.
$$







**Problem 6** For the function $f(Î¸) = \sin 3 Î¸$, state explicit formulae for its Fourier coefficients
$$
\hat f_k := {1 \over 2Ï€} \int_0^{2Ï€} f(Î¸) {\rm e}^{-{\rm i} k Î¸} {\rm d}Î¸
$$
and  their discrete approximation:
$$
\hat f_k^n := {1 \over n} \sum_{j=0}^{n-1} f(Î¸_j) {\rm e}^{-{\rm i} k Î¸_j}.
$$
for _all_ integers $k$, $n = 1,2,â€¦$, where $Î¸_j = 2Ï€ j/n$.








**Problem 7** Consider orthogonal polynomials
$$
H_n(x) = 2^n x^n + O (x^{n-1})
$$
as $x â†’ âˆ$ and $n = 0, 1, 2, â€¦$,  orthogonal with respect to the inner product
$$
\langle f, g \rangle = \int_{-âˆ}^âˆ f(x) g(x) w(x) {\rm d}x, \qquad w(x) = \exp(-x^2)
$$
Construct $H_0(x)$, $H_1(x)$, $H_2(x)$ and hence show that $H_3(x) = 8x^3-12x$. You may use without proof the formulae
$$
\int_{-âˆ}^âˆ w(x) {\rm d}x = \sqrt{Ï€}, \int_{-âˆ}^âˆ x^2 w(x) {\rm d}x = \sqrt{Ï€}/2,
\int_{-âˆ}^âˆ x^4 w(x) {\rm d}x = 3\sqrt{Ï€}/4.
$$





**Problem 8(a)** Derive the 3-point Gauss quadrature formula
$$
\int_{-âˆ}^âˆ f(x) \exp(-x^2) {\rm d}x â‰ˆ w_1 f(x_1) + w_2 f(x_2) + w_3 f(x_3)
$$
with analytic expressions for $x_j$ and $w_j$.





**Problem 8(b)** Compute the 2-point and 3-point Gaussian quadrature rules associated with $w(x) = 1$ on $[-1,1]$.





**Problem 9** Solve Problem 4(b) from PS8 using **Lemma 12 (discrete orthogonality)** with
$w(x) = 1/\sqrt{1-x^2}$ on $[-1,1]$. That is, use the connection of $T_n(x)$ with $\cos n Î¸$ to
show that the Discrete Cosine Transform
$$
C_n := \begin{bmatrix}
\sqrt{1/n} \\
 & \sqrt{2/n} \\
 && â‹± \\
 &&& \sqrt{2/n}
 \end{bmatrix}
\begin{bmatrix}
    1 & â‹¯ & 1\\
    \cos Î¸_1 & â‹¯ & \cos Î¸_n \\
    â‹® & â‹± & â‹® \\
    \cos (n-1)Î¸_1 & â‹¯ & \cos (n-1)Î¸_n
\end{bmatrix}
$$
for $Î¸_j = Ï€(j-1/2)/n$ is an orthogonal matrix.


